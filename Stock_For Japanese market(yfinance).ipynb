{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7c26feb8-2857-49ad-b961-f2d30f4a28b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: yfinance in c:\\users\\admin\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (0.2.55)\n",
      "Requirement already satisfied: pandas>=1.3.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from yfinance) (2.2.3)\n",
      "Requirement already satisfied: numpy>=1.16.5 in c:\\users\\admin\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from yfinance) (2.2.4)\n",
      "Requirement already satisfied: requests>=2.31 in c:\\users\\admin\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from yfinance) (2.32.3)\n",
      "Requirement already satisfied: multitasking>=0.0.7 in c:\\users\\admin\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from yfinance) (0.0.11)\n",
      "Requirement already satisfied: platformdirs>=2.0.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from yfinance) (4.3.7)\n",
      "Requirement already satisfied: pytz>=2022.5 in c:\\users\\admin\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from yfinance) (2025.2)\n",
      "Requirement already satisfied: frozendict>=2.3.4 in c:\\users\\admin\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from yfinance) (2.4.6)\n",
      "Requirement already satisfied: peewee>=3.16.2 in c:\\users\\admin\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from yfinance) (3.17.9)\n",
      "Requirement already satisfied: beautifulsoup4>=4.11.1 in c:\\users\\admin\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from yfinance) (4.13.3)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\admin\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from beautifulsoup4>=4.11.1->yfinance) (2.6)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from beautifulsoup4>=4.11.1->yfinance) (4.13.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\admin\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pandas>=1.3.0->yfinance) (2.9.0.post0)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\admin\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pandas>=1.3.0->yfinance) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\admin\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from python-dateutil>=2.8.2->pandas>=1.3.0->yfinance) (1.17.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\admin\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests>=2.31->yfinance) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\admin\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests>=2.31->yfinance) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\admin\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests>=2.31->yfinance) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\admin\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests>=2.31->yfinance) (2025.1.31)\n"
     ]
    }
   ],
   "source": [
    "!pip install yfinance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e51a78a7-594a-4447-880a-db021d06891a",
   "metadata": {},
   "source": [
    "## Input the Target code and Time period, use the following code the get each stock's information (Including open, high, low, close and volumn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "13f7594d-648d-4337-bb28-08e43abb2759",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â­ï¸ å·²è·³è¿‡ï¼ˆé4ä½æ•°å­—ï¼‰ï¼š\n",
      "  - 146A: ã‚³ãƒ­ãƒ³ãƒ“ã‚¢ãƒ»ãƒ¯ãƒ¼ã‚¯ã‚¹\n",
      "  - 391A: å±±å¿ \n",
      "\n",
      "==============================\n",
      "â–¶ï¸ æŠ“å– 8927 â€” æ˜è±Šã‚¨ãƒ³ã‚¿ãƒ¼ãƒ—ãƒ©ã‚¤ã‚º\n",
      "  â€¢ Yahoo æŠ“å– 8927.Tï¼ˆå°è¯• 1/7ï¼‰\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "1 Failed download:\n",
      "['8927.T']: YFRateLimitError('Too Many Requests. Rate limited. Try after a while.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    âŒ éé™æµé”™è¯¯ï¼šempty dataframe\n",
      "  â€¢ Stooq å…œåº• 8927.jp\n",
      "âœ… [8927] æ˜è±Šã‚¨ãƒ³ã‚¿ãƒ¼ãƒ—ãƒ©ã‚¤ã‚º -> å·²ä¿å­˜å•åªæ•°æ®ï¼šdata\\8927_stooq_2015-10-01_to_2025-10-01.csvï¼ˆ2,442 è¡Œï¼‰\n",
      "â³ ç­‰å¾… 16.0s å†æŠ“ä¸‹ä¸€åªâ€¦\n",
      "\n",
      "==============================\n",
      "â–¶ï¸ æŠ“å– 8869 â€” æ˜å’Œåœ°æ‰€\n",
      "  â€¢ Yahoo æŠ“å– 8869.Tï¼ˆå°è¯• 1/7ï¼‰\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "1 Failed download:\n",
      "['8869.T']: YFRateLimitError('Too Many Requests. Rate limited. Try after a while.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    âŒ éé™æµé”™è¯¯ï¼šempty dataframe\n",
      "  â€¢ Stooq å…œåº• 8869.jp\n",
      "âœ… [8869] æ˜å’Œåœ°æ‰€ -> å·²ä¿å­˜å•åªæ•°æ®ï¼šdata\\8869_stooq_2015-10-01_to_2025-10-01.csvï¼ˆ2,442 è¡Œï¼‰\n",
      "â³ ç­‰å¾… 19.7s å†æŠ“ä¸‹ä¸€åªâ€¦\n",
      "\n",
      "==============================\n",
      "â–¶ï¸ æŠ“å– 8871 â€” ã‚´ãƒ¼ãƒ«ãƒ‰ã‚¯ãƒ¬ã‚¹ãƒˆ\n",
      "  â€¢ Yahoo æŠ“å– 8871.Tï¼ˆå°è¯• 1/7ï¼‰\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "1 Failed download:\n",
      "['8871.T']: YFRateLimitError('Too Many Requests. Rate limited. Try after a while.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    âŒ éé™æµé”™è¯¯ï¼šempty dataframe\n",
      "  â€¢ Stooq å…œåº• 8871.jp\n",
      "âœ… [8871] ã‚´ãƒ¼ãƒ«ãƒ‰ã‚¯ãƒ¬ã‚¹ãƒˆ -> å·²ä¿å­˜å•åªæ•°æ®ï¼šdata\\8871_stooq_2015-10-01_to_2025-10-01.csvï¼ˆ2,442 è¡Œï¼‰\n",
      "â³ ç­‰å¾… 14.2s å†æŠ“ä¸‹ä¸€åªâ€¦\n",
      "\n",
      "==============================\n",
      "â–¶ï¸ æŠ“å– 8877 â€” ã‚¨ã‚¹ãƒªãƒ¼ãƒ‰\n",
      "  â€¢ Yahoo æŠ“å– 8877.Tï¼ˆå°è¯• 1/7ï¼‰\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "1 Failed download:\n",
      "['8877.T']: YFRateLimitError('Too Many Requests. Rate limited. Try after a while.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    âŒ éé™æµé”™è¯¯ï¼šempty dataframe\n",
      "  â€¢ Stooq å…œåº• 8877.jp\n",
      "âœ… [8877] ã‚¨ã‚¹ãƒªãƒ¼ãƒ‰ -> å·²ä¿å­˜å•åªæ•°æ®ï¼šdata\\8877_stooq_2015-10-01_to_2025-10-01.csvï¼ˆ2,442 è¡Œï¼‰\n",
      "â³ ç­‰å¾… 16.8s å†æŠ“ä¸‹ä¸€åªâ€¦\n",
      "\n",
      "==============================\n",
      "â–¶ï¸ æŠ“å– 3489 â€” ãƒ•ã‚§ã‚¤ã‚¹ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯\n",
      "  â€¢ Yahoo æŠ“å– 3489.Tï¼ˆå°è¯• 1/7ï¼‰\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "1 Failed download:\n",
      "['3489.T']: YFRateLimitError('Too Many Requests. Rate limited. Try after a while.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    âŒ éé™æµé”™è¯¯ï¼šempty dataframe\n",
      "  â€¢ Stooq å…œåº• 3489.jp\n",
      "âœ… [3489] ãƒ•ã‚§ã‚¤ã‚¹ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ -> å·²ä¿å­˜å•åªæ•°æ®ï¼šdata\\3489_stooq_2015-10-01_to_2025-10-01.csvï¼ˆ1,841 è¡Œï¼‰\n",
      "â³ ç­‰å¾… 20.0s å†æŠ“ä¸‹ä¸€åªâ€¦\n",
      "\n",
      "==============================\n",
      "â–¶ï¸ æŠ“å– 3236 â€” ãƒ—ãƒ­ãƒ‘ã‚¹ãƒˆ\n",
      "  â€¢ Yahoo æŠ“å– 3236.Tï¼ˆå°è¯• 1/7ï¼‰\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "1 Failed download:\n",
      "['3236.T']: YFRateLimitError('Too Many Requests. Rate limited. Try after a while.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    âŒ éé™æµé”™è¯¯ï¼šempty dataframe\n",
      "  â€¢ Stooq å…œåº• 3236.jp\n",
      "âœ… [3236] ãƒ—ãƒ­ãƒ‘ã‚¹ãƒˆ -> å·²ä¿å­˜å•åªæ•°æ®ï¼šdata\\3236_stooq_2015-10-01_to_2025-10-01.csvï¼ˆ2,442 è¡Œï¼‰\n",
      "â³ ç­‰å¾… 17.4s å†æŠ“ä¸‹ä¸€åªâ€¦\n",
      "\n",
      "==============================\n",
      "â–¶ï¸ æŠ“å– 3242 â€” ã‚¢ãƒ¼ãƒãƒãƒƒãƒˆã‚³ãƒ¼ãƒãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³\n",
      "  â€¢ Yahoo æŠ“å– 3242.Tï¼ˆå°è¯• 1/7ï¼‰\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "1 Failed download:\n",
      "['3242.T']: YFRateLimitError('Too Many Requests. Rate limited. Try after a while.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    âŒ éé™æµé”™è¯¯ï¼šempty dataframe\n",
      "  â€¢ Stooq å…œåº• 3242.jp\n",
      "âœ… [3242] ã‚¢ãƒ¼ãƒãƒãƒƒãƒˆã‚³ãƒ¼ãƒãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ -> å·²ä¿å­˜å•åªæ•°æ®ï¼šdata\\3242_stooq_2015-10-01_to_2025-10-01.csvï¼ˆ2,442 è¡Œï¼‰\n",
      "â³ ç­‰å¾… 19.4s å†æŠ“ä¸‹ä¸€åªâ€¦\n",
      "\n",
      "==============================\n",
      "â–¶ï¸ æŠ“å– 3238 â€” ã‚»ãƒ³ãƒˆãƒ©ãƒ«ç·åˆé–‹ç™º\n",
      "  â€¢ Yahoo æŠ“å– 3238.Tï¼ˆå°è¯• 1/7ï¼‰\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "1 Failed download:\n",
      "['3238.T']: YFRateLimitError('Too Many Requests. Rate limited. Try after a while.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    âŒ éé™æµé”™è¯¯ï¼šempty dataframe\n",
      "  â€¢ Stooq å…œåº• 3238.jp\n",
      "âœ… [3238] ã‚»ãƒ³ãƒˆãƒ©ãƒ«ç·åˆé–‹ç™º -> å·²ä¿å­˜å•åªæ•°æ®ï¼šdata\\3238_stooq_2015-10-01_to_2025-10-01.csvï¼ˆ2,441 è¡Œï¼‰\n",
      "â³ ç­‰å¾… 14.7s å†æŠ“ä¸‹ä¸€åªâ€¦\n",
      "\n",
      "==============================\n",
      "â–¶ï¸ æŠ“å– 3245 â€” ãƒ‡ã‚£ã‚¢ãƒ»ãƒ©ã‚¤ãƒ•\n",
      "  â€¢ Yahoo æŠ“å– 3245.Tï¼ˆå°è¯• 1/7ï¼‰\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "1 Failed download:\n",
      "['3245.T']: YFRateLimitError('Too Many Requests. Rate limited. Try after a while.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    âŒ éé™æµé”™è¯¯ï¼šempty dataframe\n",
      "  â€¢ Stooq å…œåº• 3245.jp\n",
      "âœ… [3245] ãƒ‡ã‚£ã‚¢ãƒ»ãƒ©ã‚¤ãƒ• -> å·²ä¿å­˜å•åªæ•°æ®ï¼šdata\\3245_stooq_2015-10-01_to_2025-10-01.csvï¼ˆ2,442 è¡Œï¼‰\n",
      "â³ ç­‰å¾… 13.5s å†æŠ“ä¸‹ä¸€åªâ€¦\n",
      "\n",
      "==============================\n",
      "â–¶ï¸ æŠ“å– 3246 â€” ã‚³ãƒ¼ã‚»ãƒ¼ã‚¢ãƒ¼ãƒ«ã‚¤ãƒ¼\n",
      "  â€¢ Yahoo æŠ“å– 3246.Tï¼ˆå°è¯• 1/7ï¼‰\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "1 Failed download:\n",
      "['3246.T']: YFRateLimitError('Too Many Requests. Rate limited. Try after a while.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    âŒ éé™æµé”™è¯¯ï¼šempty dataframe\n",
      "  â€¢ Stooq å…œåº• 3246.jp\n",
      "âœ… [3246] ã‚³ãƒ¼ã‚»ãƒ¼ã‚¢ãƒ¼ãƒ«ã‚¤ãƒ¼ -> å·²ä¿å­˜å•åªæ•°æ®ï¼šdata\\3246_stooq_2015-10-01_to_2025-10-01.csvï¼ˆ2,442 è¡Œï¼‰\n",
      "â³ ç­‰å¾… 16.0s å†æŠ“ä¸‹ä¸€åªâ€¦\n",
      "\n",
      "==============================\n",
      "â–¶ï¸ æŠ“å– 3486 â€” ã‚°ãƒ­ãƒ¼ãƒãƒ«ãƒ»ãƒªãƒ³ã‚¯ãƒ»ãƒãƒã‚¸ãƒ¡ãƒ³ãƒˆ\n",
      "  â€¢ Yahoo æŠ“å– 3486.Tï¼ˆå°è¯• 1/7ï¼‰\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "1 Failed download:\n",
      "['3486.T']: YFRateLimitError('Too Many Requests. Rate limited. Try after a while.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    âŒ éé™æµé”™è¯¯ï¼šempty dataframe\n",
      "  â€¢ Stooq å…œåº• 3486.jp\n",
      "âœ… [3486] ã‚°ãƒ­ãƒ¼ãƒãƒ«ãƒ»ãƒªãƒ³ã‚¯ãƒ»ãƒãƒã‚¸ãƒ¡ãƒ³ãƒˆ -> å·²ä¿å­˜å•åªæ•°æ®ï¼šdata\\3486_stooq_2015-10-01_to_2025-10-01.csvï¼ˆ1,903 è¡Œï¼‰\n",
      "â³ ç­‰å¾… 12.7s å†æŠ“ä¸‹ä¸€åªâ€¦\n",
      "\n",
      "==============================\n",
      "â–¶ï¸ æŠ“å– 3498 â€” éœãƒ¶é–¢ã‚­ãƒ£ãƒ”ã‚¿ãƒ«\n",
      "  â€¢ Yahoo æŠ“å– 3498.Tï¼ˆå°è¯• 1/7ï¼‰\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "1 Failed download:\n",
      "['3498.T']: YFRateLimitError('Too Many Requests. Rate limited. Try after a while.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    âŒ éé™æµé”™è¯¯ï¼šempty dataframe\n",
      "  â€¢ Stooq å…œåº• 3498.jp\n",
      "âœ… [3498] éœãƒ¶é–¢ã‚­ãƒ£ãƒ”ã‚¿ãƒ« -> å·²ä¿å­˜å•åªæ•°æ®ï¼šdata\\3498_stooq_2015-10-01_to_2025-10-01.csvï¼ˆ1,667 è¡Œï¼‰\n",
      "â³ ç­‰å¾… 17.8s å†æŠ“ä¸‹ä¸€åªâ€¦\n",
      "\n",
      "==============================\n",
      "â–¶ï¸ æŠ“å– 8844 â€” ã‚³ã‚¹ãƒ¢ã‚¹ã‚¤ãƒ‹ã‚·ã‚¢\n",
      "  â€¢ Yahoo æŠ“å– 8844.Tï¼ˆå°è¯• 1/7ï¼‰\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "1 Failed download:\n",
      "['8844.T']: YFRateLimitError('Too Many Requests. Rate limited. Try after a while.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    âŒ éé™æµé”™è¯¯ï¼šempty dataframe\n",
      "  â€¢ Stooq å…œåº• 8844.jp\n",
      "âœ… [8844] ã‚³ã‚¹ãƒ¢ã‚¹ã‚¤ãƒ‹ã‚·ã‚¢ -> å·²ä¿å­˜å•åªæ•°æ®ï¼šdata\\8844_stooq_2015-10-01_to_2025-10-01.csvï¼ˆ2,442 è¡Œï¼‰\n",
      "â³ ç­‰å¾… 16.0s å†æŠ“ä¸‹ä¸€åªâ€¦\n",
      "\n",
      "==============================\n",
      "â–¶ï¸ æŠ“å– 8881 â€” æ—¥ç¥ã‚°ãƒ«ãƒ¼ãƒ—ãƒ›ãƒ¼ãƒ«ãƒ‡ã‚£ãƒ³ã‚°ã‚¹\n",
      "  â€¢ Yahoo æŠ“å– 8881.Tï¼ˆå°è¯• 1/7ï¼‰\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "1 Failed download:\n",
      "['8881.T']: YFRateLimitError('Too Many Requests. Rate limited. Try after a while.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    âŒ éé™æµé”™è¯¯ï¼šempty dataframe\n",
      "  â€¢ Stooq å…œåº• 8881.jp\n",
      "âœ… [8881] æ—¥ç¥ã‚°ãƒ«ãƒ¼ãƒ—ãƒ›ãƒ¼ãƒ«ãƒ‡ã‚£ãƒ³ã‚°ã‚¹ -> å·²ä¿å­˜å•åªæ•°æ®ï¼šdata\\8881_stooq_2015-10-01_to_2025-10-01.csvï¼ˆ2,442 è¡Œï¼‰\n",
      "â³ ç­‰å¾… 16.2s å†æŠ“ä¸‹ä¸€åªâ€¦\n",
      "\n",
      "==============================\n",
      "â–¶ï¸ æŠ“å– 8887 â€” ã‚·ãƒ¼ãƒ©ãƒ›ãƒ¼ãƒ«ãƒ‡ã‚£ãƒ³ã‚°ã‚¹\n",
      "  â€¢ Yahoo æŠ“å– 8887.Tï¼ˆå°è¯• 1/7ï¼‰\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "1 Failed download:\n",
      "['8887.T']: YFRateLimitError('Too Many Requests. Rate limited. Try after a while.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    âŒ éé™æµé”™è¯¯ï¼šempty dataframe\n",
      "  â€¢ Stooq å…œåº• 8887.jp\n",
      "âœ… [8887] ã‚·ãƒ¼ãƒ©ãƒ›ãƒ¼ãƒ«ãƒ‡ã‚£ãƒ³ã‚°ã‚¹ -> å·²ä¿å­˜å•åªæ•°æ®ï¼šdata\\8887_stooq_2015-10-01_to_2025-10-01.csvï¼ˆ2,442 è¡Œï¼‰\n",
      "â³ ç­‰å¾… 12.0s å†æŠ“ä¸‹ä¸€åªâ€¦\n",
      "\n",
      "==============================\n",
      "â–¶ï¸ æŠ“å– 8892 â€” æ—¥æœ¬ã‚¨ã‚¹ã‚³ãƒ³\n",
      "  â€¢ Yahoo æŠ“å– 8892.Tï¼ˆå°è¯• 1/7ï¼‰\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "1 Failed download:\n",
      "['8892.T']: YFRateLimitError('Too Many Requests. Rate limited. Try after a while.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    âŒ éé™æµé”™è¯¯ï¼šempty dataframe\n",
      "  â€¢ Stooq å…œåº• 8892.jp\n",
      "âœ… [8892] æ—¥æœ¬ã‚¨ã‚¹ã‚³ãƒ³ -> å·²ä¿å­˜å•åªæ•°æ®ï¼šdata\\8892_stooq_2015-10-01_to_2025-10-01.csvï¼ˆ2,442 è¡Œï¼‰\n",
      "â³ ç­‰å¾… 15.0s å†æŠ“ä¸‹ä¸€åªâ€¦\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ADMIN\\AppData\\Local\\Temp\\ipykernel_16472\\3552996870.py:187: FutureWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  frames.append(pd.read_csv(path, parse_dates=[\"Date\"], infer_datetime_format=True))\n",
      "C:\\Users\\ADMIN\\AppData\\Local\\Temp\\ipykernel_16472\\3552996870.py:187: FutureWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  frames.append(pd.read_csv(path, parse_dates=[\"Date\"], infer_datetime_format=True))\n",
      "C:\\Users\\ADMIN\\AppData\\Local\\Temp\\ipykernel_16472\\3552996870.py:187: FutureWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  frames.append(pd.read_csv(path, parse_dates=[\"Date\"], infer_datetime_format=True))\n",
      "C:\\Users\\ADMIN\\AppData\\Local\\Temp\\ipykernel_16472\\3552996870.py:187: FutureWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  frames.append(pd.read_csv(path, parse_dates=[\"Date\"], infer_datetime_format=True))\n",
      "C:\\Users\\ADMIN\\AppData\\Local\\Temp\\ipykernel_16472\\3552996870.py:187: FutureWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  frames.append(pd.read_csv(path, parse_dates=[\"Date\"], infer_datetime_format=True))\n",
      "C:\\Users\\ADMIN\\AppData\\Local\\Temp\\ipykernel_16472\\3552996870.py:187: FutureWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  frames.append(pd.read_csv(path, parse_dates=[\"Date\"], infer_datetime_format=True))\n",
      "C:\\Users\\ADMIN\\AppData\\Local\\Temp\\ipykernel_16472\\3552996870.py:187: FutureWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  frames.append(pd.read_csv(path, parse_dates=[\"Date\"], infer_datetime_format=True))\n",
      "C:\\Users\\ADMIN\\AppData\\Local\\Temp\\ipykernel_16472\\3552996870.py:187: FutureWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  frames.append(pd.read_csv(path, parse_dates=[\"Date\"], infer_datetime_format=True))\n",
      "C:\\Users\\ADMIN\\AppData\\Local\\Temp\\ipykernel_16472\\3552996870.py:187: FutureWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  frames.append(pd.read_csv(path, parse_dates=[\"Date\"], infer_datetime_format=True))\n",
      "C:\\Users\\ADMIN\\AppData\\Local\\Temp\\ipykernel_16472\\3552996870.py:187: FutureWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  frames.append(pd.read_csv(path, parse_dates=[\"Date\"], infer_datetime_format=True))\n",
      "C:\\Users\\ADMIN\\AppData\\Local\\Temp\\ipykernel_16472\\3552996870.py:187: FutureWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  frames.append(pd.read_csv(path, parse_dates=[\"Date\"], infer_datetime_format=True))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“¦ åˆå¹¶å®Œæˆï¼šjp_tse_prices_combined_2015-10-01_to_2025-10-01.csvï¼ˆ37,156 è¡Œï¼‰\n",
      "\n",
      "â€”â€” æŠ“å–ç»“æœ â€”â€”\n",
      "âœ… æˆåŠŸï¼š16 | âŒ å¤±è´¥ï¼š0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ADMIN\\AppData\\Local\\Temp\\ipykernel_16472\\3552996870.py:187: FutureWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  frames.append(pd.read_csv(path, parse_dates=[\"Date\"], infer_datetime_format=True))\n",
      "C:\\Users\\ADMIN\\AppData\\Local\\Temp\\ipykernel_16472\\3552996870.py:187: FutureWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  frames.append(pd.read_csv(path, parse_dates=[\"Date\"], infer_datetime_format=True))\n",
      "C:\\Users\\ADMIN\\AppData\\Local\\Temp\\ipykernel_16472\\3552996870.py:187: FutureWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  frames.append(pd.read_csv(path, parse_dates=[\"Date\"], infer_datetime_format=True))\n",
      "C:\\Users\\ADMIN\\AppData\\Local\\Temp\\ipykernel_16472\\3552996870.py:187: FutureWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  frames.append(pd.read_csv(path, parse_dates=[\"Date\"], infer_datetime_format=True))\n",
      "C:\\Users\\ADMIN\\AppData\\Local\\Temp\\ipykernel_16472\\3552996870.py:187: FutureWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  frames.append(pd.read_csv(path, parse_dates=[\"Date\"], infer_datetime_format=True))\n"
     ]
    }
   ],
   "source": [
    "# ======================================================\n",
    "# è¶…ç¨³ç‰ˆï¼šTSE æ—¥è‚¡æ•°æ®æŠ“å–ï¼ˆYahooä¼˜å…ˆï¼ŒStooqå…œåº•ï¼‰\n",
    "# ä¸¥æ ¼å•åªä¸²è¡Œ + å¼ºç­‰å¾… + æŒ‡æ•°é€€é¿ + æ–­ç‚¹ç»­è·‘\n",
    "# ======================================================\n",
    "\n",
    "import os, time, random, math\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "\n",
    "# å¤‡æº\n",
    "try:\n",
    "    from pandas_datareader import data as pdr\n",
    "    HAVE_PDR = True\n",
    "except Exception:\n",
    "    HAVE_PDR = False\n",
    "\n",
    "# -------------------------\n",
    "# è¾“å…¥\n",
    "# -------------------------\n",
    "companies = {\n",
    "    \"8927\": \"æ˜è±Šã‚¨ãƒ³ã‚¿ãƒ¼ãƒ—ãƒ©ã‚¤ã‚º\",\n",
    "    \"8869\": \"æ˜å’Œåœ°æ‰€\",\n",
    "    \"8871\": \"ã‚´ãƒ¼ãƒ«ãƒ‰ã‚¯ãƒ¬ã‚¹ãƒˆ\",\n",
    "    \"8877\": \"ã‚¨ã‚¹ãƒªãƒ¼ãƒ‰\",\n",
    "    \"3489\": \"ãƒ•ã‚§ã‚¤ã‚¹ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯\",\n",
    "    \"146A\": \"ã‚³ãƒ­ãƒ³ãƒ“ã‚¢ãƒ»ãƒ¯ãƒ¼ã‚¯ã‚¹\",         # é4ä½æ•°å­— -> è·³è¿‡\n",
    "    \"3236\": \"ãƒ—ãƒ­ãƒ‘ã‚¹ãƒˆ\",\n",
    "    \"3242\": \"ã‚¢ãƒ¼ãƒãƒãƒƒãƒˆã‚³ãƒ¼ãƒãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³\",\n",
    "    \"3238\": \"ã‚»ãƒ³ãƒˆãƒ©ãƒ«ç·åˆé–‹ç™º\",\n",
    "    \"3245\": \"ãƒ‡ã‚£ã‚¢ãƒ»ãƒ©ã‚¤ãƒ•\",\n",
    "    \"3246\": \"ã‚³ãƒ¼ã‚»ãƒ¼ã‚¢ãƒ¼ãƒ«ã‚¤ãƒ¼\",\n",
    "    \"3486\": \"ã‚°ãƒ­ãƒ¼ãƒãƒ«ãƒ»ãƒªãƒ³ã‚¯ãƒ»ãƒãƒã‚¸ãƒ¡ãƒ³ãƒˆ\",\n",
    "    \"3498\": \"éœãƒ¶é–¢ã‚­ãƒ£ãƒ”ã‚¿ãƒ«\",\n",
    "    \"391A\": \"å±±å¿ \",                       # é4ä½æ•°å­— -> è·³è¿‡\n",
    "    \"8844\": \"ã‚³ã‚¹ãƒ¢ã‚¹ã‚¤ãƒ‹ã‚·ã‚¢\",\n",
    "    \"8881\": \"æ—¥ç¥ã‚°ãƒ«ãƒ¼ãƒ—ãƒ›ãƒ¼ãƒ«ãƒ‡ã‚£ãƒ³ã‚°ã‚¹\",\n",
    "    \"8887\": \"ã‚·ãƒ¼ãƒ©ãƒ›ãƒ¼ãƒ«ãƒ‡ã‚£ãƒ³ã‚°ã‚¹\",\n",
    "    \"8892\": \"æ—¥æœ¬ã‚¨ã‚¹ã‚³ãƒ³\"\n",
    "}\n",
    "start_date = \"2015-10-01\"\n",
    "end_date   = \"2025-10-01\"\n",
    "\n",
    "# -------------------------\n",
    "# å‚æ•°ï¼ˆå¯æŒ‰éœ€è°ƒå¤§/è°ƒå°ï¼‰\n",
    "# -------------------------\n",
    "YF_MAX_RETRIES   = 7          # yfinance æœ€å¤§é‡è¯•\n",
    "BASE_SLEEP       = 2.5        # æŒ‡æ•°é€€é¿åŸºå‡†ç§’\n",
    "BETWEEN_TICKERS  = (12, 20)   # æ¯åªä¹‹é—´çš„å¼ºåˆ¶ç­‰å¾…åŒºé—´ï¼ˆç§’ï¼‰\n",
    "AUTO_ADJUST      = True       # True=å¤æƒä»·ï¼ŒFalse=åŸå§‹ä»·\n",
    "OUT_DIR          = \"data\"\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "\n",
    "# -------------------------\n",
    "# è¾…åŠ©å‡½æ•°\n",
    "# -------------------------\n",
    "def human_sleep(seconds: float):\n",
    "    seconds = max(0.5, float(seconds))\n",
    "    time.sleep(seconds)\n",
    "\n",
    "def sleep_between_tickers():\n",
    "    wait = random.uniform(*BETWEEN_TICKERS)\n",
    "    print(f\"â³ ç­‰å¾… {wait:.1f}s å†æŠ“ä¸‹ä¸€åªâ€¦\")\n",
    "    human_sleep(wait)\n",
    "\n",
    "def save_one_df(df: pd.DataFrame, code: str, name: str, source: str):\n",
    "    if df is None or df.empty:\n",
    "        return False\n",
    "    df = df.copy()\n",
    "    df[\"Code\"] = code\n",
    "    df[\"Company\"] = name\n",
    "    df[\"Source\"] = source\n",
    "    # ç»Ÿä¸€åˆ—å\n",
    "    df.columns = [c.title() if isinstance(c, str) else c for c in df.columns]\n",
    "    # è½åœ°å•æ–‡ä»¶\n",
    "    fn = os.path.join(OUT_DIR, f\"{code}_{source}_{start_date}_to_{end_date}.csv\")\n",
    "    df.to_csv(fn, encoding=\"utf-8-sig\")\n",
    "    print(f\"âœ… [{code}] {name} -> å·²ä¿å­˜å•åªæ•°æ®ï¼š{fn}ï¼ˆ{len(df):,} è¡Œï¼‰\")\n",
    "    return True\n",
    "\n",
    "def fetch_yahoo(code: str):\n",
    "    \"\"\"ç”¨ yfinance ä¸²è¡ŒæŠ“å–å•åªï¼ŒæŒ‡æ•°é€€é¿é‡è¯•\"\"\"\n",
    "    tk = f\"{code}.T\"\n",
    "    attempt = 0\n",
    "    while attempt < YF_MAX_RETRIES:\n",
    "        try:\n",
    "            print(f\"  â€¢ Yahoo æŠ“å– {tk}ï¼ˆå°è¯• {attempt+1}/{YF_MAX_RETRIES}ï¼‰\")\n",
    "            df = yf.download(\n",
    "                tickers=[tk],\n",
    "                start=start_date,\n",
    "                end=end_date,\n",
    "                auto_adjust=AUTO_ADJUST,\n",
    "                group_by=\"ticker\",\n",
    "                threads=False,\n",
    "                progress=False,\n",
    "                interval=\"1d\",\n",
    "            )\n",
    "            # yfinance å•åªæ—¶å¯èƒ½è¿”å›æ™®é€šåˆ—æˆ–å¤šé‡åˆ—\n",
    "            if df is None or df.empty:\n",
    "                raise RuntimeError(\"empty dataframe\")\n",
    "            if isinstance(df.columns, pd.MultiIndex):\n",
    "                if tk in df.columns.get_level_values(0):\n",
    "                    df = df[tk].copy()\n",
    "                else:\n",
    "                    # å¤šé‡åˆ—ä½†ä¸å«ç›®æ ‡ -> è§†ä½œå¤±è´¥\n",
    "                    raise RuntimeError(\"missing ticker in returned columns\")\n",
    "            return df\n",
    "        except Exception as e:\n",
    "            msg = str(e)\n",
    "            # ç²—åˆ¤é™æµ/ç½‘ç»œ\n",
    "            if any(k in msg for k in [\"Too Many Requests\", \"Rate\", \"429\", \"timed out\"]):\n",
    "                sleep_s = BASE_SLEEP * (2 ** attempt) + random.uniform(0, 1.5)\n",
    "                print(f\"    âš ï¸ é™æµ/ç½‘ç»œé—®é¢˜ï¼š{msg} -> {sleep_s:.1f}s åé‡è¯•\")\n",
    "                human_sleep(sleep_s)\n",
    "                attempt += 1\n",
    "            else:\n",
    "                print(f\"    âŒ éé™æµé”™è¯¯ï¼š{msg}\")\n",
    "                break\n",
    "    return None\n",
    "\n",
    "def fetch_stooq(code: str):\n",
    "    \"\"\"ç”¨ Stooq å…œåº•ï¼ˆè¦†ç›–æœ‰é™ï¼‰â€”â€” ä»£ç å½¢å¦‚ 8927.jp\"\"\"\n",
    "    if not HAVE_PDR:\n",
    "        return None\n",
    "    sym = f\"{code}.jp\"\n",
    "    try:\n",
    "        print(f\"  â€¢ Stooq å…œåº• {sym}\")\n",
    "        df = pdr.DataReader(sym, \"stooq\", start=start_date, end=end_date)\n",
    "        # Stooq åˆ—åæ˜¯ Open/High/Low/Close/Volume ç­‰ï¼ˆå€’åºæˆ–æ­£åºï¼‰\n",
    "        if df is None or df.empty:\n",
    "            return None\n",
    "        # ç»Ÿä¸€æŒ‰æ—¥æœŸå‡åº\n",
    "        df = df.sort_index()\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        print(f\"    âŒ Stooq å¤±è´¥ï¼š{e}\")\n",
    "        return None\n",
    "\n",
    "# -------------------------\n",
    "# ä¸»æµç¨‹ï¼šä¸¥æ ¼å•åªä¸²è¡Œ\n",
    "# -------------------------\n",
    "numeric = {c: n for c, n in companies.items() if c.isdigit() and len(c) == 4}\n",
    "skipped = {c: n for c, n in companies.items() if c not in numeric}\n",
    "\n",
    "if skipped:\n",
    "    print(\"â­ï¸ å·²è·³è¿‡ï¼ˆé4ä½æ•°å­—ï¼‰ï¼š\")\n",
    "    for c, n in skipped.items():\n",
    "        print(f\"  - {c}: {n}\")\n",
    "\n",
    "success_codes = []\n",
    "fail_codes    = []\n",
    "\n",
    "for code, name in numeric.items():\n",
    "    print(f\"\\n==============================\")\n",
    "    print(f\"â–¶ï¸ æŠ“å– {code} â€” {name}\")\n",
    "    # å¦‚æœè¯¥ä»£ç å·²æœ‰æˆåŠŸè½åœ°æ–‡ä»¶ï¼Œè·³è¿‡ï¼ˆæ–­ç‚¹ç»­è·‘ï¼‰\n",
    "    already = [f for f in os.listdir(OUT_DIR) if f.startswith(f\"{code}_\") and f.endswith(\".csv\")]\n",
    "    if already:\n",
    "        print(f\"  ğŸ” æ£€æµ‹åˆ°å·²æœ‰æ–‡ä»¶ï¼Œè·³è¿‡æŠ“å–ï¼š{already[0]}\")\n",
    "        success_codes.append(code)\n",
    "        continue\n",
    "\n",
    "    df = fetch_yahoo(code)\n",
    "    if df is not None and save_one_df(df, code, name, \"yahoo\"):\n",
    "        success_codes.append(code)\n",
    "        sleep_between_tickers()\n",
    "        continue\n",
    "\n",
    "    # Yahoo å¤±è´¥ -> å°è¯• Stooq\n",
    "    df2 = fetch_stooq(code)\n",
    "    if df2 is not None and save_one_df(df2, code, name, \"stooq\"):\n",
    "        success_codes.append(code)\n",
    "        sleep_between_tickers()\n",
    "        continue\n",
    "\n",
    "    print(f\"  â—æœ€ç»ˆå¤±è´¥ï¼š{code} {name}\")\n",
    "    fail_codes.append(code)\n",
    "    sleep_between_tickers()\n",
    "\n",
    "# -------------------------\n",
    "# æ±‡æ€»åˆå¹¶ï¼ˆæŠŠ data/ ä¸‹çš„å•åªCSV åˆä¸ºä¸€ä»½ï¼‰\n",
    "# -------------------------\n",
    "all_paths = [os.path.join(OUT_DIR, f) for f in os.listdir(OUT_DIR) if f.endswith(\".csv\")]\n",
    "frames = []\n",
    "for path in all_paths:\n",
    "    try:\n",
    "        frames.append(pd.read_csv(path, parse_dates=[\"Date\"], infer_datetime_format=True))\n",
    "    except Exception:\n",
    "        # Stooq æ–‡ä»¶å¯èƒ½åˆ—åæ˜¯ 'Date' æˆ– 'Date' å·²åœ¨ç´¢å¼•ï¼›ä¸Šé¢çš„ to_csv ä¿è¯æœ‰ Date åˆ—\n",
    "        frames.append(pd.read_csv(path))\n",
    "\n",
    "if frames:\n",
    "    combined = pd.concat(frames, ignore_index=True)\n",
    "    # è§„èŒƒåˆ—é¡ºåº\n",
    "    front = [c for c in [\"Company\", \"Code\", \"Source\"] if c in combined.columns]\n",
    "    rest  = [c for c in combined.columns if c not in front]\n",
    "    combined = combined[front + rest]\n",
    "    out_all = f\"jp_tse_prices_combined_{start_date}_to_{end_date}.csv\"\n",
    "    combined.sort_values([\"Code\",\"Date\"], inplace=True, ignore_index=True)\n",
    "    combined.to_csv(out_all, encoding=\"utf-8-sig\", index=False)\n",
    "    print(f\"\\nğŸ“¦ åˆå¹¶å®Œæˆï¼š{out_all}ï¼ˆ{len(combined):,} è¡Œï¼‰\")\n",
    "else:\n",
    "    print(\"\\nâš ï¸ æ²¡æœ‰ä»»ä½•æˆåŠŸæ–‡ä»¶å¯åˆå¹¶ã€‚\")\n",
    "\n",
    "print(\"\\nâ€”â€” æŠ“å–ç»“æœ â€”â€”\")\n",
    "print(f\"âœ… æˆåŠŸï¼š{len(success_codes)} | âŒ å¤±è´¥ï¼š{len(fail_codes)}\")\n",
    "if fail_codes:\n",
    "    print(\"å¤±è´¥ä»£ç ï¼š\", \", \".join(fail_codes))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "934ee37b-809a-4fc9-92ff-092f12294673",
   "metadata": {},
   "source": [
    "# The stock including Alphabet may not be catched perfectedly, so try the following code and get the stock information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2709b9c2-493d-486d-8005-748b8bce7b47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… 146A ã‚³ãƒ­ãƒ³ãƒ“ã‚¢ãƒ»ãƒ¯ãƒ¼ã‚¯ã‚¹ æ•°æ®è¡Œæ•°: 371\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2024-03-28</th>\n",
       "      <td>1792.17</td>\n",
       "      <td>2022.56</td>\n",
       "      <td>1704.86</td>\n",
       "      <td>1806.72</td>\n",
       "      <td>4914169.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-03-29</th>\n",
       "      <td>1906.15</td>\n",
       "      <td>2138.96</td>\n",
       "      <td>1857.65</td>\n",
       "      <td>2078.34</td>\n",
       "      <td>4042875.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-04-01</th>\n",
       "      <td>2214.14</td>\n",
       "      <td>2417.86</td>\n",
       "      <td>2214.14</td>\n",
       "      <td>2342.68</td>\n",
       "      <td>2801499.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-04-02</th>\n",
       "      <td>2371.78</td>\n",
       "      <td>2415.43</td>\n",
       "      <td>2109.86</td>\n",
       "      <td>2134.11</td>\n",
       "      <td>1720319.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-04-03</th>\n",
       "      <td>2131.69</td>\n",
       "      <td>2294.18</td>\n",
       "      <td>1957.08</td>\n",
       "      <td>2073.48</td>\n",
       "      <td>2108134.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Open     High      Low    Close     Volume\n",
       "Date                                                     \n",
       "2024-03-28  1792.17  2022.56  1704.86  1806.72  4914169.0\n",
       "2024-03-29  1906.15  2138.96  1857.65  2078.34  4042875.0\n",
       "2024-04-01  2214.14  2417.86  2214.14  2342.68  2801499.0\n",
       "2024-04-02  2371.78  2415.43  2109.86  2134.11  1720319.0\n",
       "2024-04-03  2131.69  2294.18  1957.08  2073.48  2108134.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… 391A å±±å¿  æ•°æ®è¡Œæ•°: 0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>No data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas_datareader.data as web\n",
    "import datetime\n",
    "\n",
    "start = datetime.date(2015, 10, 1)\n",
    "end   = datetime.date(2025, 10, 1)\n",
    "\n",
    "for code, name in [(\"146A\", \"ã‚³ãƒ­ãƒ³ãƒ“ã‚¢ãƒ»ãƒ¯ãƒ¼ã‚¯ã‚¹\"), (\"391A\", \"å±±å¿ \")]:\n",
    "    symbol = f\"{code}.jp\"\n",
    "    try:\n",
    "        df = web.DataReader(symbol, \"stooq\", start, end)\n",
    "        df = df.sort_index()\n",
    "        print(f\"âœ… {code} {name} æ•°æ®è¡Œæ•°: {len(df)}\")\n",
    "        display(df.head())\n",
    "        df.to_csv(f\"{code}_stooq.csv\", encoding=\"utf-8-sig\")\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ {code} {name} è·å–å¤±è´¥: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2643345-8784-49a1-8ad7-f806e55fb7b1",
   "metadata": {},
   "source": [
    "# Combined all the csv files into 1 csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b82cc09b-056f-4e94-b324-0c872f94509f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… å·²é€‰æ‹© 17 ä¸ªæ–‡ä»¶ï¼š\n",
      " - D:/jupyter/Job/Restar/é–‹ç™ºè¨ˆç”»/XU/data/146A_stooq_2015-10-01_to_2025-10-01.csv\n",
      " - D:/jupyter/Job/Restar/é–‹ç™ºè¨ˆç”»/XU/data/3236_stooq_2015-10-01_to_2025-10-01.csv\n",
      " - D:/jupyter/Job/Restar/é–‹ç™ºè¨ˆç”»/XU/data/3238_stooq_2015-10-01_to_2025-10-01.csv\n",
      " - D:/jupyter/Job/Restar/é–‹ç™ºè¨ˆç”»/XU/data/3242_stooq_2015-10-01_to_2025-10-01.csv\n",
      " - D:/jupyter/Job/Restar/é–‹ç™ºè¨ˆç”»/XU/data/3245_stooq_2015-10-01_to_2025-10-01.csv\n",
      " - D:/jupyter/Job/Restar/é–‹ç™ºè¨ˆç”»/XU/data/3246_stooq_2015-10-01_to_2025-10-01.csv\n",
      " - D:/jupyter/Job/Restar/é–‹ç™ºè¨ˆç”»/XU/data/3486_stooq_2015-10-01_to_2025-10-01.csv\n",
      " - D:/jupyter/Job/Restar/é–‹ç™ºè¨ˆç”»/XU/data/3489_stooq_2015-10-01_to_2025-10-01.csv\n",
      " - D:/jupyter/Job/Restar/é–‹ç™ºè¨ˆç”»/XU/data/3498_stooq_2015-10-01_to_2025-10-01.csv\n",
      " - D:/jupyter/Job/Restar/é–‹ç™ºè¨ˆç”»/XU/data/8844_stooq_2015-10-01_to_2025-10-01.csv\n",
      " - D:/jupyter/Job/Restar/é–‹ç™ºè¨ˆç”»/XU/data/8869_stooq_2015-10-01_to_2025-10-01.csv\n",
      " - D:/jupyter/Job/Restar/é–‹ç™ºè¨ˆç”»/XU/data/8871_stooq_2015-10-01_to_2025-10-01.csv\n",
      " - D:/jupyter/Job/Restar/é–‹ç™ºè¨ˆç”»/XU/data/8877_stooq_2015-10-01_to_2025-10-01.csv\n",
      " - D:/jupyter/Job/Restar/é–‹ç™ºè¨ˆç”»/XU/data/8881_stooq_2015-10-01_to_2025-10-01.csv\n",
      " - D:/jupyter/Job/Restar/é–‹ç™ºè¨ˆç”»/XU/data/8887_stooq_2015-10-01_to_2025-10-01.csv\n",
      " - D:/jupyter/Job/Restar/é–‹ç™ºè¨ˆç”»/XU/data/8892_stooq_2015-10-01_to_2025-10-01.csv\n",
      " - D:/jupyter/Job/Restar/é–‹ç™ºè¨ˆç”»/XU/data/8927_stooq_2015-10-01_to_2025-10-01.csv\n",
      "\n",
      "ğŸ’¾ å·²ä¿å­˜ä¸º combined_stocks.csvï¼Œå…± 37,527 è¡Œã€‚\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import tkinter as tk\n",
    "from tkinter import filedialog\n",
    "\n",
    "# æ‰“å¼€æ–‡ä»¶é€‰æ‹©çª—å£\n",
    "root = tk.Tk()\n",
    "root.withdraw()  # ä¸æ˜¾ç¤ºä¸»çª—å£\n",
    "files = filedialog.askopenfilenames(\n",
    "    title=\"é€‰æ‹©è¦åˆå¹¶çš„CSVæ–‡ä»¶\",\n",
    "    filetypes=[(\"CSV Files\", \"*.csv\"), (\"All Files\", \"*.*\")]\n",
    ")\n",
    "\n",
    "if not files:\n",
    "    print(\"âŒ æ²¡æœ‰é€‰æ‹©ä»»ä½•æ–‡ä»¶ã€‚\")\n",
    "else:\n",
    "    print(f\"âœ… å·²é€‰æ‹© {len(files)} ä¸ªæ–‡ä»¶ï¼š\")\n",
    "    for f in files:\n",
    "        print(\" -\", f)\n",
    "\n",
    "    # è¯»å–å¹¶åˆå¹¶\n",
    "    dfs = [pd.read_csv(f, encoding=\"utf-8-sig\") for f in files]\n",
    "    combined = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "    # å»é‡ï¼ˆå¦‚æœæœ‰ Code + Date åˆ—ï¼‰\n",
    "    if {\"Code\", \"Date\"}.issubset(combined.columns):\n",
    "        combined = combined.sort_values([\"Code\", \"Date\"]).drop_duplicates([\"Code\", \"Date\"])\n",
    "\n",
    "    # ä¿å­˜\n",
    "    combined.to_csv(\"combined_stocks.csv\", index=False, encoding=\"utf-8-sig\")\n",
    "    print(f\"\\nğŸ’¾ å·²ä¿å­˜ä¸º combined_stocks.csvï¼Œå…± {len(combined):,} è¡Œã€‚\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9d07b1d-aa6f-4952-be01-29852943cb75",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "613c45b9-1a98-49bc-802d-c4146ba440a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3de7b6ae-ad07-4edb-83b4-6e6000a45635",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
