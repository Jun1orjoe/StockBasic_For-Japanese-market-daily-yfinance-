{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0ae52408-caf7-47e7-b078-9ae0849eab00",
   "metadata": {},
   "source": [
    "## Get the information of {Revenue, OperatingIncome, NetIncome} together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d53586dc-376a-49b8-a342-1953b63cbc0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved:\n",
      " - financials_yq_core_metrics.csv\n",
      " - financials_yq_audit.csv\n",
      "\n",
      "[No Quarterly Data]\n",
      "symbol CompanyNameJP\n",
      "391A.T            山忠\n",
      "\n",
      "[No Annual Data]\n",
      "symbol CompanyNameJP\n",
      "391A.T            山忠\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ADMIN\\AppData\\Local\\Temp\\ipykernel_3428\\489150770.py:109: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  audit[\"quarterly_has_data\"] = audit[\"quarterly_has_data\"].fillna(False)\n",
      "C:\\Users\\ADMIN\\AppData\\Local\\Temp\\ipykernel_3428\\489150770.py:110: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  audit[\"annual_has_data\"] = audit[\"annual_has_data\"].fillna(False)\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "# pip install yahooquery pandas numpy\n",
    "from yahooquery import Ticker\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from time import sleep\n",
    "\n",
    "# ========== 1) 目标公司清单（可按需增删） ==========\n",
    "JP_TICKERS = {\n",
    "    \"明豊エンタープライズ\": \"8927.T\",\n",
    "    \"明和地所\": \"8869.T\",\n",
    "    \"ゴールドクレスト\": \"8871.T\",\n",
    "    \"エスリード\": \"8877.T\",\n",
    "    \"フェイスネットワーク\": \"3489.T\",\n",
    "    \"コロンビア・ワークス\": \"146A.T\",     # 可能取不到数据，脚本会自动标记\n",
    "    \"プロパスト\": \"3236.T\",\n",
    "    \"アーバネットコーポレーション\": \"3242.T\",\n",
    "    \"セントラル総合開発\": \"3238.T\",\n",
    "    \"ディア・ライフ\": \"3245.T\",\n",
    "    \"コーセーアールイー\": \"3246.T\",\n",
    "    \"グローバル・リンク・マネジメント\": \"3486.T\",\n",
    "    \"霞ヶ関キャピタル\": \"3498.T\",\n",
    "    \"山忠\": \"391A.T\",                     # 可能取不到数据，脚本会自动标记\n",
    "    \"コスモスイニシア\": \"8844.T\",\n",
    "    \"日神グループホールディングス\": \"8881.T\",\n",
    "    \"シーラホールディングス\": \"8887.T\",\n",
    "    \"日本エスコン\": \"8892.T\",\n",
    "}\n",
    "\n",
    "# ========== 2) 抓取函数 ==========\n",
    "def fetch_income_df(tickers, freq=\"q\"):\n",
    "    \"\"\"\n",
    "    使用 yahooquery 批量抓取损益表。\n",
    "    freq: 'q' 为季度，'a' 为年度\n",
    "    返回 DataFrame：index 含 symbol、asOfDate；列含 TotalRevenue/OperatingIncome/NetIncome 等\n",
    "    \"\"\"\n",
    "    t = Ticker(list(tickers), asynchronous=True)\n",
    "    df = t.income_statement(frequency=freq)  # 直接返回 DataFrame（yahooquery 会合并所有股票）\n",
    "    # 兼容：若返回为空或不是 DataFrame\n",
    "    if not isinstance(df, pd.DataFrame) or df.empty:\n",
    "        return pd.DataFrame()\n",
    "    # 有些版本 index 是普通列；统一保证 symbol & asOfDate 作为列存在\n",
    "    if \"symbol\" not in df.columns and isinstance(df.index, pd.MultiIndex):\n",
    "        df = df.reset_index()\n",
    "    elif \"symbol\" not in df.columns:\n",
    "        df = df.reset_index()\n",
    "    return df\n",
    "\n",
    "# ========== 3) 主流程：季度 + 年度 ==========\n",
    "tickers_all = list(JP_TICKERS.values())\n",
    "\n",
    "df_q = fetch_income_df(tickers_all, freq=\"q\")\n",
    "df_a = fetch_income_df(tickers_all, freq=\"a\")\n",
    "\n",
    "# 标准化列名（不同版本/公司可能有大小写差异，做一层容错）\n",
    "def std_cols(df):\n",
    "    if df.empty:\n",
    "        return df\n",
    "    cols = {c: c for c in df.columns}\n",
    "    rename_map = {}\n",
    "    for c in df.columns:\n",
    "        lc = c.lower()\n",
    "        if lc == \"asofdate\": rename_map[c] = \"asOfDate\"\n",
    "        if lc == \"periodtype\": rename_map[c] = \"periodType\"\n",
    "        if lc == \"totalrevenue\": rename_map[c] = \"TotalRevenue\"\n",
    "        if lc == \"operatingincome\": rename_map[c] = \"OperatingIncome\"\n",
    "        if lc == \"netincome\": rename_map[c] = \"NetIncome\"\n",
    "        if lc == \"currencycode\": rename_map[c] = \"currencyCode\"\n",
    "    if rename_map:\n",
    "        df = df.rename(columns=rename_map)\n",
    "    return df\n",
    "\n",
    "df_q = std_cols(df_q)\n",
    "df_a = std_cols(df_a)\n",
    "\n",
    "# 只保留我们关心的核心列（存在就保留，不存在就跳过）\n",
    "CORE_COLS = [\"symbol\", \"asOfDate\", \"currencyCode\", \"TotalRevenue\", \"OperatingIncome\", \"NetIncome\", \"periodType\"]\n",
    "df_q = df_q[[c for c in CORE_COLS if c in df_q.columns]].copy() if not df_q.empty else pd.DataFrame()\n",
    "df_a = df_a[[c for c in CORE_COLS if c in df_a.columns]].copy() if not df_a.empty else pd.DataFrame()\n",
    "\n",
    "# 加入公司日文名（用映射反查）\n",
    "ticker_to_name = {v: k for k, v in JP_TICKERS.items()}\n",
    "for df in [df_q, df_a]:\n",
    "    if not df.empty:\n",
    "        df[\"CompanyNameJP\"] = df[\"symbol\"].map(ticker_to_name)\n",
    "        # 排序更易读\n",
    "        df.sort_values([\"symbol\", \"asOfDate\"], inplace=True)\n",
    "\n",
    "# ========== 4) 审计：哪些代码成功/失败 ==========\n",
    "def audit_availability(df, label):\n",
    "    \"\"\"返回每个 symbol 是否取到数据的表\"\"\"\n",
    "    if df.empty:\n",
    "        return pd.DataFrame(columns=[\"symbol\", f\"{label}_has_data\"])\n",
    "    g = (df.groupby(\"symbol\").size()\n",
    "           .rename(f\"{label}_rows\")\n",
    "           .reset_index())\n",
    "    g[f\"{label}_has_data\"] = g[f\"{label}_rows\"] > 0\n",
    "    return g[[\"symbol\", f\"{label}_has_data\"]]\n",
    "\n",
    "aud_q = audit_availability(df_q, \"quarterly\")\n",
    "aud_a = audit_availability(df_a, \"annual\")\n",
    "\n",
    "audit = pd.merge(\n",
    "    pd.DataFrame({\"symbol\": tickers_all}),\n",
    "    aud_q, on=\"symbol\", how=\"left\"\n",
    ")\n",
    "audit = pd.merge(audit, aud_a, on=\"symbol\", how=\"left\")\n",
    "audit[\"CompanyNameJP\"] = audit[\"symbol\"].map(ticker_to_name)\n",
    "audit[\"quarterly_has_data\"] = audit[\"quarterly_has_data\"].fillna(False)\n",
    "audit[\"annual_has_data\"] = audit[\"annual_has_data\"].fillna(False)\n",
    "\n",
    "# ========== 5) 输出标准化长表：方便与你的 REMETIS 合并 ==========\n",
    "def to_long(df, freq_label):\n",
    "    \"\"\"\n",
    "    宽 -> 长：\n",
    "    输出列：CompanyNameJP, symbol, asOfDate, Metric, Value, currencyCode, periodType, Freq\n",
    "    Metric ∈ {Revenue, OperatingIncome, NetIncome}\n",
    "    \"\"\"\n",
    "    if df.empty:\n",
    "        return pd.DataFrame(columns=[\n",
    "            \"CompanyNameJP\", \"symbol\", \"asOfDate\", \"Metric\", \"Value\", \"currencyCode\", \"periodType\", \"Freq\"\n",
    "        ])\n",
    "    slim = df.copy()\n",
    "    # 兼容没有 periodType/currencyCode 的情况\n",
    "    if \"periodType\" not in slim.columns: slim[\"periodType\"] = np.nan\n",
    "    if \"currencyCode\" not in slim.columns: slim[\"currencyCode\"] = np.nan\n",
    "    keep = [\"CompanyNameJP\", \"symbol\", \"asOfDate\", \"currencyCode\", \"periodType\",\n",
    "            \"TotalRevenue\", \"OperatingIncome\", \"NetIncome\"]\n",
    "    keep = [c for c in keep if c in slim.columns]\n",
    "    slim = slim[keep]\n",
    "    # 重命名为标准Metric\n",
    "    rename_metric = {\n",
    "        \"TotalRevenue\": \"Revenue\",\n",
    "        \"OperatingIncome\": \"OperatingIncome\",\n",
    "        \"NetIncome\": \"NetIncome\"\n",
    "    }\n",
    "    slim = slim.rename(columns=rename_metric)\n",
    "    # 宽转长\n",
    "    long = slim.melt(\n",
    "        id_vars=[c for c in [\"CompanyNameJP\", \"symbol\", \"asOfDate\", \"currencyCode\", \"periodType\"] if c in slim.columns],\n",
    "        value_vars=[c for c in [\"Revenue\", \"OperatingIncome\", \"NetIncome\"] if c in slim.columns],\n",
    "        var_name=\"Metric\", value_name=\"Value\"\n",
    "    )\n",
    "    long[\"Freq\"] = freq_label\n",
    "    # 排序\n",
    "    long = long.sort_values([\"symbol\", \"asOfDate\", \"Metric\"]).reset_index(drop=True)\n",
    "    return long\n",
    "\n",
    "long_q = to_long(df_q, \"Quarterly\")\n",
    "long_a = to_long(df_a, \"Annual\")\n",
    "\n",
    "# 合并两个频率\n",
    "financials_long = pd.concat([long_q, long_a], ignore_index=True)\n",
    "\n",
    "# ========== 6) 保存到 CSV ==========\n",
    "financials_long.to_csv(\"financials_yq_core_metrics.csv\", index=False, encoding=\"utf-8-sig\")\n",
    "audit.sort_values(\"symbol\").to_csv(\"financials_yq_audit.csv\", index=False, encoding=\"utf-8-sig\")\n",
    "\n",
    "print(\"✅ Saved:\")\n",
    "print(\" - financials_yq_core_metrics.csv\")\n",
    "print(\" - financials_yq_audit.csv\")\n",
    "\n",
    "# 提示哪些公司无数据\n",
    "no_q = audit.loc[~audit[\"quarterly_has_data\"], [\"symbol\", \"CompanyNameJP\"]]\n",
    "no_a = audit.loc[~audit[\"annual_has_data\"], [\"symbol\", \"CompanyNameJP\"]]\n",
    "print(\"\\n[No Quarterly Data]\")\n",
    "print(no_q.to_string(index=False))\n",
    "print(\"\\n[No Annual Data]\")\n",
    "print(no_a.to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bd95cd1-54d8-40c9-8084-df5dba95bff2",
   "metadata": {},
   "source": [
    "## Get specific Information of each company(Maybe better than the code above）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c2d012fb-2e59-4b81-9bf6-d1b23b74b47a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Fetching: 明豊エンタープライズ (8927.T)\n",
      "==> Fetching: 明和地所 (8869.T)\n",
      "==> Fetching: ゴールドクレスト (8871.T)\n",
      "==> Fetching: エスリード (8877.T)\n",
      "==> Fetching: フェイスネットワーク (3489.T)\n",
      "==> Fetching: コロンビア・ワークス (146A.T)\n",
      "==> Fetching: プロパスト (3236.T)\n",
      "==> Fetching: アーバネットコーポレーション (3242.T)\n",
      "==> Fetching: セントラル総合開発 (3238.T)\n",
      "==> Fetching: ディア・ライフ (3245.T)\n",
      "==> Fetching: コーセーアールイー (3246.T)\n",
      "==> Fetching: グローバル・リンク・マネジメント (3486.T)\n",
      "==> Fetching: 霞ヶ関キャピタル (3498.T)\n",
      "==> Fetching: 山忠 (391A.T)\n",
      "==> Fetching: コスモスイニシア (8844.T)\n",
      "==> Fetching: 日神グループホールディングス (8881.T)\n",
      "==> Fetching: シーラホールディングス (8887.T)\n",
      "==> Fetching: 日本エスコン (8892.T)\n",
      "Saved combined_all_financial_data.csv (81 rows)\n",
      "Saved combined_income_statement_quarterly.csv (122 rows)\n",
      "Saved combined_income_statement_annual.csv (165 rows)\n",
      "Saved combined_balance_sheet_quarterly.csv (55 rows)\n",
      "Saved combined_balance_sheet_annual.csv (79 rows)\n",
      "\n",
      "✅ Done.\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "# pip install yahooquery pandas numpy\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from yahooquery import Ticker\n",
    "from time import sleep\n",
    "\n",
    "# ===== 1) 目标公司清单（可增删）=====\n",
    "JP_TICKERS = {\n",
    "    \"明豊エンタープライズ\": \"8927.T\",\n",
    "    \"明和地所\": \"8869.T\",\n",
    "    \"ゴールドクレスト\": \"8871.T\",\n",
    "    \"エスリード\": \"8877.T\",\n",
    "    \"フェイスネットワーク\": \"3489.T\",\n",
    "    \"コロンビア・ワークス\": \"146A.T\",   # 可能无数据\n",
    "    \"プロパスト\": \"3236.T\",\n",
    "    \"アーバネットコーポレーション\": \"3242.T\",\n",
    "    \"セントラル総合開発\": \"3238.T\",\n",
    "    \"ディア・ライフ\": \"3245.T\",\n",
    "    \"コーセーアールイー\": \"3246.T\",\n",
    "    \"グローバル・リンク・マネジメント\": \"3486.T\",\n",
    "    \"霞ヶ関キャピタル\": \"3498.T\",\n",
    "    \"山忠\": \"391A.T\",                   # 可能无数据\n",
    "    \"コスモスイニシア\": \"8844.T\",\n",
    "    \"日神グループホールディングス\": \"8881.T\",\n",
    "    \"シーラホールディングス\": \"8887.T\",\n",
    "    \"日本エスコン\": \"8892.T\",\n",
    "}\n",
    "\n",
    "# ===== 2) 工具函数 =====\n",
    "def ensure_dir(path: str):\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path, exist_ok=True)\n",
    "\n",
    "def to_df(obj):\n",
    "    \"\"\"把 yahooquery 返回的对象转为 DataFrame（若已是DF则直接返回）\"\"\"\n",
    "    if isinstance(obj, pd.DataFrame):\n",
    "        return obj.copy()\n",
    "    try:\n",
    "        return pd.DataFrame(obj)\n",
    "    except Exception:\n",
    "        return pd.DataFrame()\n",
    "\n",
    "def normalize_df(df, symbol=None, company_name=None):\n",
    "    \"\"\"确保有 symbol 列、重置索引，附加公司名。\"\"\"\n",
    "    if df is None or df.empty:\n",
    "        return pd.DataFrame()\n",
    "    if \"symbol\" not in df.columns:\n",
    "        # 如果是 MultiIndex 或普通索引，把索引转列\n",
    "        df = df.reset_index()\n",
    "        if \"symbol\" not in df.columns and symbol is not None:\n",
    "            df[\"symbol\"] = symbol\n",
    "    if company_name is not None and \"CompanyNameJP\" not in df.columns:\n",
    "        df[\"CompanyNameJP\"] = company_name\n",
    "    # asOfDate/periodType 等列名大小写的容错\n",
    "    rename_map = {}\n",
    "    for c in df.columns:\n",
    "        lc = c.lower()\n",
    "        if lc == \"asofdate\": rename_map[c] = \"asOfDate\"\n",
    "        if lc == \"periodtype\": rename_map[c] = \"periodType\"\n",
    "        if lc == \"currencycode\": rename_map[c] = \"currencyCode\"\n",
    "    if rename_map:\n",
    "        df = df.rename(columns=rename_map)\n",
    "    return df\n",
    "\n",
    "# ===== 3) 抓取并保存（逐公司 & 汇总）=====\n",
    "combined_all = []      # all_financial_data 的汇总\n",
    "combined_inc_q = []    # income_statement 季度汇总\n",
    "combined_inc_a = []    # income_statement 年度汇总\n",
    "combined_bs_q  = []    # balance_sheet 季度汇总\n",
    "combined_bs_a  = []    # balance_sheet 年度汇总\n",
    "\n",
    "for name, sym in JP_TICKERS.items():\n",
    "    print(f\"==> Fetching: {name} ({sym})\")\n",
    "    out_dir = os.path.join(os.getcwd(), sym.replace(\".\", \"_\"))  # e.g., 8927_T\n",
    "    ensure_dir(out_dir)\n",
    "\n",
    "    try:\n",
    "        t = Ticker(sym)\n",
    "\n",
    "        # 3.1 all_financial_data\n",
    "        afd = to_df(t.all_financial_data())\n",
    "        afd = normalize_df(afd, symbol=sym, company_name=name)\n",
    "        afd.to_csv(os.path.join(out_dir, \"all_financial_data.csv\"),\n",
    "                   index=False, encoding=\"utf-8-sig\")\n",
    "        if not afd.empty:\n",
    "            combined_all.append(afd)\n",
    "\n",
    "        # 3.2 income_statement（季度）\n",
    "        inc_q = t.income_statement(frequency=\"q\")\n",
    "        inc_q = to_df(inc_q)\n",
    "        inc_q = normalize_df(inc_q, symbol=sym, company_name=name)\n",
    "        inc_q.to_csv(os.path.join(out_dir, \"income_statement_quarterly.csv\"),\n",
    "                     index=False, encoding=\"utf-8-sig\")\n",
    "        if not inc_q.empty:\n",
    "            combined_inc_q.append(inc_q)\n",
    "\n",
    "        # 3.3 income_statement（年度）\n",
    "        inc_a = t.income_statement(frequency=\"a\")\n",
    "        inc_a = to_df(inc_a)\n",
    "        inc_a = normalize_df(inc_a, symbol=sym, company_name=name)\n",
    "        inc_a.to_csv(os.path.join(out_dir, \"income_statement_annual.csv\"),\n",
    "                     index=False, encoding=\"utf-8-sig\")\n",
    "        if not inc_a.empty:\n",
    "            combined_inc_a.append(inc_a)\n",
    "\n",
    "        # 3.4 balance_sheet（季度）\n",
    "        bs_q = t.balance_sheet(frequency=\"q\")\n",
    "        bs_q = to_df(bs_q)\n",
    "        bs_q = normalize_df(bs_q, symbol=sym, company_name=name)\n",
    "        bs_q.to_csv(os.path.join(out_dir, \"balance_sheet_quarterly.csv\"),\n",
    "                    index=False, encoding=\"utf-8-sig\")\n",
    "        if not bs_q.empty:\n",
    "            combined_bs_q.append(bs_q)\n",
    "\n",
    "        # 3.5 balance_sheet（年度）\n",
    "        bs_a = t.balance_sheet(frequency=\"a\")\n",
    "        bs_a = to_df(bs_a)\n",
    "        bs_a = normalize_df(bs_a, symbol=sym, company_name=name)\n",
    "        bs_a.to_csv(os.path.join(out_dir, \"balance_sheet_annual.csv\"),\n",
    "                    index=False, encoding=\"utf-8-sig\")\n",
    "        if not bs_a.empty:\n",
    "            combined_bs_a.append(bs_a)\n",
    "\n",
    "        # 友好限速（可视网速调小）\n",
    "        sleep(0.4)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"[WARN] {sym} failed: {e}\")\n",
    "        continue\n",
    "\n",
    "# ===== 4) 汇总落盘（可直接用于后续分析/merge）=====\n",
    "def save_combined(dfs, fname):\n",
    "    if not dfs:\n",
    "        # 输出空壳，便于后续流程不报错\n",
    "        pd.DataFrame().to_csv(fname, index=False, encoding=\"utf-8-sig\")\n",
    "        print(f\"Saved empty {fname} (no data)\")\n",
    "    else:\n",
    "        combined = pd.concat(dfs, ignore_index=True)\n",
    "        # 统一排序更易读\n",
    "        if \"symbol\" in combined.columns:\n",
    "            sort_cols = [c for c in [\"symbol\", \"asOfDate\"] if c in combined.columns]\n",
    "            if sort_cols:\n",
    "                combined = combined.sort_values(sort_cols)\n",
    "        combined.to_csv(fname, index=False, encoding=\"utf-8-sig\")\n",
    "        print(f\"Saved {fname} ({len(combined)} rows)\")\n",
    "\n",
    "save_combined(combined_all, \"combined_all_financial_data.csv\")\n",
    "save_combined(combined_inc_q, \"combined_income_statement_quarterly.csv\")\n",
    "save_combined(combined_inc_a, \"combined_income_statement_annual.csv\")\n",
    "save_combined(combined_bs_q,  \"combined_balance_sheet_quarterly.csv\")\n",
    "save_combined(combined_bs_a,  \"combined_balance_sheet_annual.csv\")\n",
    "\n",
    "print(\"\\n✅ Done.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05db5c74-5b03-4629-9f70-b62f3f82c21b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a28ec6f-ec8a-41a2-86c0-af9bfda2ba45",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ac87cba-19e3-441d-ad86-c09a159a0b44",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
